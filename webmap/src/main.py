import os 
from pathlib import Path
from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from huggingface_hub import InferenceClient
from pydantic import BaseModel
from typing import Optional

# 1. LOAD CONFIG V√Ä KH·ªûI T·∫†O
# Load .env t·ª´ c√πng th∆∞ m·ª•c v·ªõi file main.py
env_path = Path(__file__).parent / ".env"
load_dotenv(dotenv_path=env_path)

HF_TOKEN = os.getenv("HF_TOKEN")
if not HF_TOKEN:
    raise ValueError(f"HF_TOKEN not found in .env file at {env_path}")

client = InferenceClient(token=HF_TOKEN)
app = FastAPI(title="WebMap AI Backend", version="1.0.0")

# C·∫•u h√¨nh CORS ƒë·ªÉ cho ph√©p website React g·ªçi ƒë·∫øn
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Trong production, thay b·∫±ng domain c·ª• th·ªÉ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# 2. MODELS V√Ä SCHEMAS
class SentimentInput(BaseModel):
    review: str

class ChatInput(BaseModel):
    message: str
    context: Optional[str] = None  # Th√¥ng tin ƒë·ªãa ƒëi·ªÉm hi·ªán t·∫°i
    max_tokens: int = 200

class PlaceRecommendInput(BaseModel):
    location: str
    preferences: Optional[str] = None

# 3. ENDPOINTS CHO C√ÅC CH·ª®C NƒÇNG

@app.get("/")
def read_root():
    return {"message": "WebMap AI Backend ƒëang ch·∫°y!", "status": "ok"}

@app.get("/health")
def health_check():
    """Ki·ªÉm tra tr·∫°ng th√°i server"""
    return {"status": "healthy", "hf_connected": True}

@app.post("/analyze/sentiment")
def analyze_sentiment(data: SentimentInput):
    """Ph√¢n t√≠ch c·∫£m x√∫c t·ª´ review du l·ªãch."""
    try:
        result = client.text_classification(
            data.review,
            model="lxyuan/distilbert-base-multilingual-cased-sentiments-student" 
        )
        # Chuy·ªÉn ƒë·ªïi label sang ti·∫øng Vi·ªát
        label_map = {
            "positive": "T√≠ch c·ª±c üòä",
            "negative": "Ti√™u c·ª±c üòû",
            "neutral": "Trung l·∫≠p üòê"
        }
        return {
            "label": label_map.get(result[0].label, result[0].label),
            "original_label": result[0].label,
            "score": round(result[0].score * 100, 1),
            "review": data.review
        }
    except Exception as e:
        print(f"L·ªói Sentiment Analysis: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/chat/travel")
def chat_travel_assistant(data: ChatInput):
    """Chatbot h·ªó tr·ª£ du l·ªãch - tr·∫£ l·ªùi c√¢u h·ªèi v·ªÅ ƒë·ªãa ƒëi·ªÉm."""
    try:
        # T·∫°o messages cho chat completion
        messages = [
            {"role": "system", "content": "B·∫°n l√† tr·ª£ l√Ω du l·ªãch th√¥ng minh. Tr·∫£ l·ªùi ng·∫Øn g·ªçn, h·ªØu √≠ch b·∫±ng ti·∫øng Vi·ªát."},
        ]
        
        if data.context:
            messages.append({"role": "user", "content": f"T√¥i ƒëang ·ªü {data.context}. {data.message}"})
        else:
            messages.append({"role": "user", "content": data.message})
        
        # S·ª≠ d·ª•ng chat_completion v·ªõi model mi·ªÖn ph√≠
        response = client.chat_completion(
            messages=messages,
            model="meta-llama/Llama-3.2-3B-Instruct",
            max_tokens=data.max_tokens,
            temperature=0.7
        )
        
        # L·∫•y n·ªôi dung response
        result = response.choices[0].message.content
        
        return {
            "response": result.strip() if result else "Xin l·ªói, kh√¥ng c√≥ ph·∫£n h·ªìi.",
            "context": data.context
        }
    except Exception as e:
        print(f"L·ªói Chat: {e}")
        # Fallback response n·∫øu API l·ªói
        return {
            "response": f"Xin l·ªói, t√¥i ƒëang g·∫∑p s·ª± c·ªë: {str(e)[:100]}",
            "error": str(e)
        }

@app.post("/recommend/places")
def recommend_places(data: PlaceRecommendInput):
    """G·ª£i √Ω ƒë·ªãa ƒëi·ªÉm d·ª±a tr√™n s·ªü th√≠ch."""
    try:
        content = f"G·ª£i √Ω 3 ƒë·ªãa ƒëi·ªÉm du l·ªãch g·∫ßn {data.location}"
        if data.preferences:
            content += f" ph√π h·ª£p v·ªõi s·ªü th√≠ch: {data.preferences}"
        content += ". Tr·∫£ l·ªùi ng·∫Øn g·ªçn b·∫±ng ti·∫øng Vi·ªát."
        
        messages = [
            {"role": "system", "content": "B·∫°n l√† chuy√™n gia du l·ªãch Vi·ªát Nam."},
            {"role": "user", "content": content}
        ]
        
        response = client.chat_completion(
            messages=messages,
            model="meta-llama/Llama-3.2-3B-Instruct",
            max_tokens=150,
            temperature=0.8
        )
        
        result = response.choices[0].message.content
        
        return {
            "recommendations": result.strip() if result else "Kh√¥ng c√≥ g·ª£i √Ω.",
            "location": data.location
        }
    except Exception as e:
        print(f"L·ªói Recommendation: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/summarize/place")
def summarize_place(data: PlaceRecommendInput):
    """T√≥m t·∫Øt th√¥ng tin v·ªÅ m·ªôt ƒë·ªãa ƒëi·ªÉm."""
    try:
        messages = [
            {"role": "system", "content": "B·∫°n l√† h∆∞·ªõng d·∫´n vi√™n du l·ªãch."},
            {"role": "user", "content": f"M√¥ t·∫£ ng·∫Øn g·ªçn v·ªÅ {data.location} trong 2-3 c√¢u b·∫±ng ti·∫øng Vi·ªát. N√™u ƒëi·ªÉm n·ªïi b·∫≠t nh·∫•t."}
        ]
        
        response = client.chat_completion(
            messages=messages,
            model="meta-llama/Llama-3.2-3B-Instruct",
            max_tokens=100,
            temperature=0.5
        )
        
        result = response.choices[0].message.content
        
        return {
            "summary": result.strip() if result else "Kh√¥ng c√≥ th√¥ng tin.",
            "location": data.location
        }
    except Exception as e:
        print(f"L·ªói Summarize: {e}")
        raise HTTPException(status_code=500, detail=str(e))

